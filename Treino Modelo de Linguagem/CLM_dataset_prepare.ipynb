{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q"
      ],
      "metadata": {
        "id": "IRR-PR3HM7O9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/doutorado/P_IA368DD_2023S/aula4.5')\n",
        "\n",
        "import gc"
      ],
      "metadata": {
        "id": "tM7nlCkAKJ7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import glob"
      ],
      "metadata": {
        "id": "0j7HbC0cPC9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "bf3FVqVaM2gR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduc_mc4_data = \"sample-1gb.txt\"\n",
        "if not os.path.exists(reduc_mc4_data):\n",
        "    !gsutil cp gs://unicamp-dl/ia025a_2022s1/aula9/sample-1gb.txt .\n",
        "else:\n",
        "    print(\"Samples file already downloaded...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrP_Z3b5JxWC",
        "outputId": "f7e509bc-9e8d-4c4b-df85-66a85c11b58c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples file already downloaded...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")"
      ],
      "metadata": {
        "id": "7_9qsTksOYqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "SAMPLES_SIZE=10000\n",
        "with open(reduc_mc4_data) as inputFile:\n",
        "  lines = inputFile.readlines()\n",
        "blocked_samples = []\n",
        "\n",
        "\n",
        "\n",
        "for i in range(int(len(lines) // SAMPLES_SIZE)):\n",
        "  normalized_samples = []\n",
        "  sample = lines[(i * SAMPLES_SIZE):(i * SAMPLES_SIZE + SAMPLES_SIZE)]\n",
        "  tokenized_sample = tokenizer(sample, padding='max_length', max_length=512)\n",
        "\n",
        "  del sample\n",
        "\n",
        "  for j in range(len(tokenized_sample['input_ids'])):\n",
        "    for k in range(int(len(tokenized_sample['input_ids'][j]) // 512)):\n",
        "      normalized_samples.append({'input_ids': tokenized_sample['input_ids'][j][(k * 512):(k * 512 + 512)],\n",
        "                                          'attention_mask': tokenized_sample['attention_mask'][j][(k * 512):(k * 512 + 512)]})\n",
        "  with open(\"tokenized/tokenized_samples_{:02d}.pkl\".format(i), \"wb\") as outputFile:\n",
        "        pickle.dump(tokenized_sample, outputFile, pickle.HIGHEST_PROTOCOL)\n",
        "  del tokenized_sample\n",
        "\n",
        "  with open(\"normalized/normalized_samples_{:02d}.pkl\".format(i), \"wb\") as outputFile:\n",
        "        pickle.dump(normalized_samples, outputFile, pickle.HIGHEST_PROTOCOL)\n",
        "  del normalized_samples\n",
        "  gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8qcZWzQMHeo",
        "outputId": "afab22fa-bb9c-47f0-f01a-6b05241d5e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 32min 24s, sys: 57 s, total: 33min 21s\n",
            "Wall time: 24min 47s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIhtc0djNneg",
        "outputId": "3def7b92-9235-42a3-d25b-3a6b7faaf2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLM_dataset_prepare.ipynb  sample-1gb.txt  Untitled0.ipynb\n",
            "normalized\t\t   tokenized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_block_files = glob.glob(\"tokenized_samples_*\")\n",
        "for k, block_filename in enumerate(tokenized_block_files):\n",
        "\n",
        "    all_tokenized_samples = []\n",
        "    \n",
        "    print(\"Reading file {}...\".format(block_filename))\n",
        "    \n",
        "    with open(block_filename, 'rb') as inputFile:\n",
        "        block_data = pickle.load(inputFile)\n",
        "        \n",
        "    for i in range(len(block_data['input_ids'])):\n",
        "        \n",
        "#         print(\"{} - len(block_data['input_ids'][{}]={}\".format(i, i, len(block_data['input_ids'][i])))\n",
        "        \n",
        "        for j in range(int(len(block_data['input_ids'][i]) // 512)):\n",
        "          print(j)\n",
        "          raise;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "GouzximrVysH",
        "outputId": "e49c14f6-40fd-4e70-fe8a-36716d0b43ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading file tokenized_samples_00.pkl...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-0cfff77205be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#         print(\"{} - len(block_data['input_ids'][{}]={}\".format(i, i, len(block_data['input_ids'][i])))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mTEXT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TEXT_CHUNK_SIZE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(block_data['input_ids'][i])#  [(0 * 512):(0 * 512 + 512)])#[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Po6suTTWxz3",
        "outputId": "7d1d7a28-b20c-4c77-8f59-b188f6276fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7329"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "7329 / 512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fecwpGLRYJDN",
        "outputId": "165ebdc0-e1a1-49a9-957a-52baaa65c8b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.314453125"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(block_data['input_ids'][i]) % 512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7gU_VuQW3CF",
        "outputId": "a490c586-a79a-4a69-bf2f-72dfc052393c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "161"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oFI454oMYG3j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}